{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネットワークの学習\n",
    "\n",
    "## データ駆動\n",
    "\n",
    "機械学習においてはデータが命である\n",
    "\n",
    "データからパターンを見つけ出し、データから答えを導く出すのが機械学習の本質である\n",
    "\n",
    "ここで、入力データからデータの本質的なパターンを導き出す変換器を**特徴量**と呼ぶ\n",
    "\n",
    "### 特徴量の抽出の歴史\n",
    "最も単純な分類である線形分類においては、特徴量を抽出する必要はなく、入力データから有限回の学習により問題を解くことが可能だった\n",
    "\n",
    "これは最初に行ったパーセプトロンによるAND, OR等の演算子の実装において証明されたように「パーセプトロンの収束原理」として知られている\n",
    "\n",
    "一方、非線形分類問題は入力データからの自動的な学習が不可能であり、特徴量を抽出する必要が出てきた\n",
    "\n",
    "当初は、特徴量の抽出からデータの学習（アルゴリズムの実装）まで全て人の手で行われており、このモデルは**エクスパートシステム**と呼ばれる\n",
    "\n",
    "その後、特徴量はデータサイエンティストと呼ばれる人々によって抽出されるようになり、抽出された特徴量を**機械学習アルゴリズム**（SVM, kNNなど）を用いて自動的に学習することが可能になった\n",
    "\n",
    "そして近年話題となった**ニューラルネットワーク（ディープラーニング）**においては、特徴量の抽出からデータの学習までを全てコンピュータによって行われるようになっている\n",
    "\n",
    "![machine_learning_history](./img/machine_learning_history.png)\n",
    "\n",
    "### パラメータの最適化と損失関数\n",
    "機械学習およびニューラルネットワークにおいては、データの学習とはすなわち**パラメータの最適化**である\n",
    "\n",
    "例えばニューラルネットワークは、重みとバイアスというパラメータの値を少しずつ変化させ、計算結果が教師データと近い値になるように学習を行っている\n",
    "\n",
    "この時、計算結果と教師データとの誤差を表現する関数を**損失関数**と呼び、この損失関数を最小化することが学習の目的となる\n",
    "\n",
    "関数の最小値を求める場合、数学的には微分という手法が用いられる\n",
    "\n",
    "微分値とは「ある瞬間における変化の量」と定義される値のことであり、わかりやすく言えば、グラフの接線の傾きのことである\n",
    "\n",
    "簡単のため二次関数を例にすると下図の通り、微分値が0になる（接線の傾きが0になる）点が関数の最小値点であり、パラメータの最適点であると考えることができる\n",
    "\n",
    "![loss_function_optimization](./img/loss_function_optimization.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
