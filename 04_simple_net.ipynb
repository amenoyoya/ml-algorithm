{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 Array{Float64,2}:\n",
       " 0.2  0.2  -0.4\n",
       " 0.3  0.3  -0.6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "@test: 参考書との比較（正しく計算されているか確認）\n",
    "\"\"\"\n",
    "# ニューラルネットワーク実装読み込み\n",
    "include(\"./lib/Neuron.jl\")\n",
    "include(\"./lib/Functions.jl\")\n",
    "\n",
    "# 数値微分による勾配計算\n",
    "## 関数(Array{Float64,2})::Float64, 入力値::Array{Float64,2} -> 勾配::Array{Float64,2}\n",
    "numeric_gradient(f, x::Array{Float64,2})::Array{Float64,2} = begin\n",
    "    h = 1e-4 # 10^(-4)\n",
    "    grad = Array{Float64, 2}(undef, size(x, 1), size(x, 2)) # xと同じ次元の行列を生成\n",
    "    # 各変数ごとの数値微分を行列にまとめる\n",
    "    for row in 1:size(x, 1), col in 1:size(x, 2)\n",
    "        # 指定indexの変数に対する中心差分を求める\n",
    "        org = x[row, col]\n",
    "        x[row, col] = org + h\n",
    "        f1 = f(x) # f([..., x[row, col] + h, ...]) -> Float64\n",
    "        x[row, col] = org - h\n",
    "        f2 = f(x) # f([..., x[row, col] - h, ...]) -> Float64\n",
    "        grad[row, col] = (f1 - f2) / 2h # (row, col)番目の変数に対する数値微分\n",
    "        x[row, col] = org # x[i]の値をもとに戻す\n",
    "    end\n",
    "    return grad\n",
    "end\n",
    "    \n",
    "# シンプルなニューラルネットワーク\n",
    "SimpleNet() = Network(1,\n",
    "    [\n",
    "        zeros(1, 3) # 1 x 3 Array{Float64,2} bias_1 [0 0 0]\n",
    "    ],\n",
    "    [\n",
    "        zeros(2, 3) # 2 x 3 Array{Float64,2} weight_1 [0 0 0; 0 0 0]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 活性関数を使わず、ソフトマックス関数で出力するだけの推論処理\n",
    "predict(net::Network, x::Array{Float64,2})::Array{Float64,2} = softmax(x * net.w[1] + net.b[1])\n",
    "\n",
    "# 損失関数: 交差エントロピー誤差\n",
    "loss(net::Network, x::Array{Float64,2}, t::Array{Float64,2})::Float64 = cross_entropy_error(predict(net, x), t)\n",
    "\n",
    "x = [0.6 0.9]\n",
    "t = [0.0 0.0 1.0]\n",
    "\n",
    "net = SimpleNet()\n",
    "\n",
    "# 勾配計算\n",
    "## 2 x 3 Array{Float64,2} [0.2 0.2 -0.4; 0.3 0.3 -0.6] になればOK\n",
    "dW = numeric_gradient(w->loss(net, x, t), net.w[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
